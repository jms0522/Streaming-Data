# 🚀 멀티 파이프라인 프로젝트

멀티 파이프라인 프로젝트에 오신 것을 환영합니다! 이 리포지토리는 데이터 중심의 애플리케이션을 위해 다양한 데이터 파이프라인을 구축하고, 관리하며, 배포하는 것을 목표로 합니다.

## 🌟 주요 기능

	•	데이터 수집 파이프라인: 다양한 소스로부터 데이터를 효율적으로 수집하고 저장합니다.
	•	ETL 파이프라인: 데이터를 추출(Extract), 변환(Transform), 로드(Load)하여 분석할 수 있도록 준비합니다.
	•	실시간 스트리밍 파이프라인: Kafka와 Spark를 사용해 실시간으로 데이터를 처리합니다.
	•	배치 처리 파이프라인: 대량의 데이터를 일정 시간에 맞춰 처리합니다.
	•	데이터 웨어하우징 파이프라인: 데이터를 확장 가능하고 안정적인 스토리지 솔루션에 저장하고 관리합니다.
	•	데이터 시각화 파이프라인: Kibana와 Grafana를 사용하여 인사이트 있는 대시보드를 만듭니다.

## 🛠️ 사용 기술

이 프로젝트는 확장 가능한 파이프라인을 구축하기 위해 다양한 기술을 활용합니다:

	•	Python: 스크립트 및 ETL 프로세스를 개발하는 데 사용되는 주요 언어입니다.
	•	Apache Kafka: 실시간 데이터 스트리밍 및 처리를 위해 사용됩니다.
	•	Apache Spark: 배치 및 스트리밍 모드에서 대규모 데이터 처리를 수행합니다.
	•	Airflow: 복잡한 워크플로를 조정하고 파이프라인의 일정 실행을 관리합니다.
	•	Docker: 일관된 환경을 보장하기 위해 서비스의 컨테이너화를 담당합니다.
	•	Elasticsearch, Logstash, Kibana (ELK Stack): 로그 데이터를 검색, 분석 및 시각화할 수 있는 전체 파이프라인을 제공합니다.
	•	Grafana: 메트릭과 로그를 시각화하고 모니터링하는 데 사용됩니다.

## 📁 프로젝트 구조




## 🚀 시작하기

### 사전 요구사항

	•	Docker 및 Docker Compose: Docker가 시스템에 설치되어 있어야 합니다.
	•	Python 3.8+: ETL 스크립트 및 Airflow DAG을 실행하는 데 필요합니다.
	•	Apache Kafka: 실시간 스트리밍을 위해 설정되어야 합니다.
	•	Apache Spark: 실시간 및 배치 데이터 처리를 위해 필요합니다.

 ## 📊 모니터링 및 로깅

	•	Grafana: 파이프라인 성능 및 메트릭을 모니터링합니다.
	•	Kibana: 다양한 파이프라인의 로그 데이터를 분석하고 시각화합니다.
	•	Airflow UI: DAG과 태스크의 상태를 모니터링합니다.
  •	Kafka UI: kafka 상태와 사용자 편의성을 증대합니다.

## 🧑‍💻 작성자

	•	Your Name - 장민수 Jangminsoo


