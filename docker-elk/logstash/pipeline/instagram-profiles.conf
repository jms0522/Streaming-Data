input {
  kafka {
    bootstrap_servers => "kafka-1:29092,kafka-2:29093,kafka-3:29094" # Kafka 브로커 주소
    topics => ["instagram_scrapper_api"] # Kafka 토픽에 설정한 토픽 이름 여기서 설정
    group_id => "logstash_group"
    codec => "json"
  }
}

filter {
  # JSON 데이터 파싱
  json {
    source => "message"
    target => "parsed_data"  # 파싱된 JSON 데이터를 저장할 타겟 필드
  }

  # parsed_data 하위 필드들을 변환 및 매핑
  mutate {
    rename => {
      "[parsed_data][full_name]" => "full_name"
      "[parsed_data][id]" => "id"
      "[parsed_data][is_new]" => "is_new"
      "[parsed_data][is_private]" => "is_private"
      "[parsed_data][is_verified]" => "is_verified"
      "[parsed_data][latest_reel_media]" => "latest_reel_media"
      "[parsed_data][profile_pic_id]" => "profile_pic_id"
      "[parsed_data][profile_pic_url]" => "profile_pic_url"
      "[parsed_data][username]" => "username"
    }

    # 데이터 타입 변환
    convert => {
      "is_new" => "boolean"
      "is_private" => "boolean"
      "is_verified" => "boolean"
      "latest_reel_media" => "integer"
    }

    # 파싱된 원본 데이터 제거
    remove_field => ["parsed_data"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "instagram_profiles" # 인덱스 이름
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
  }

  stdout {
    codec => rubydebug
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "instagram_profiles" # 인덱스 이름 여기서 설정
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
  }

  stdout {
    codec => rubydebug
  }
}
